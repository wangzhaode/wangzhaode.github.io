<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> MNN模型支持：面壁小钢炮MiniCPM-V-4 | Zhaode's blog </title> <meta name="author" content="Zhaode Wang"> <meta name="description" content="A blog about technology and life. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, blog"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhaode.wang/blog/2025/minicpm/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Zhaode's blog </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">MNN模型支持：面壁小钢炮MiniCPM-V-4</h1> <p class="post-meta"> Created on September 05, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/mnn"> <i class="fa-solid fa-tag fa-sm"></i> MNN</a>   <a href="/blog/category/llm"> <i class="fa-solid fa-tag fa-sm"></i> llm</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>面壁智能的MiniCPM模型，自发布以来就被誉为“端侧小钢炮”，以其在端侧设备上出色的多模态能力而闻名。MNN作为一个端侧推理框架，支持目前主流的端侧模型，端侧小钢炮的模型也不例外。这里记录一下MNN对MiniCPM-V-4的支持过程。</p> <h2 id="minicpm-v-4模型介绍">MiniCPM-V-4模型介绍</h2> <p>首先，简单了解一下 <strong>MiniCPM-V-4</strong>：</p> <ul> <li> <strong>参数规模</strong>：4.1B，由一个400M的视觉编码器和一个3B的语言模型组成。</li> <li> <strong>模型性能</strong>：在权威的OpenCompass评测中得分69.0，表现优于许多同量级模型。在旗舰手机上，可以实现流畅的实时交互（首token延迟&lt;2s，解码速度&gt;17 token/s）。</li> </ul> <p>对这个模型的支持主要工作是对他的视觉处理部分的支持</p> <h2 id="模型导出">模型导出</h2> <p>我们主要针对模型的视觉处理部分（Vision Encoder）进行了三项关键优化。</p> <p><strong>优化策略一：变动态搜索为静态计算的图像切分</strong></p> <p><strong>问题背景</strong>：为了处理高清大图，MiniCPM-V 4.0会智能地将图像切分成多个小块（Slices）。原始实现需要通过一个搜索算法，在运行时动态计算出最佳的切分网格，这个过程在端侧会带来不必要的延迟。</p> <p><strong>我们的解决方案</strong>：我们发现这个搜索过程可以被一个确定性的数学模型替代。通过分析图像的面积、长宽比等几何特征，我们可以用一次前向计算直接得出最优的切分方案。</p> <p><strong>优化后的核心算法逻辑</strong>：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">calculate_image_processing_plan</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">max_slice_nums</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">scale_resolution</span><span class="o">=</span><span class="mi">448</span><span class="p">):</span>
    <span class="n">original_height</span><span class="p">,</span> <span class="n">original_width</span> <span class="o">=</span> <span class="n">original_size</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">original_width</span> <span class="o">*</span> <span class="n">original_height</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">scale_resolution</span> <span class="o">*</span> <span class="n">scale_resolution</span><span class="p">)</span>
    <span class="n">multiple</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="nf">ceil</span><span class="p">(</span><span class="n">ratio</span><span class="p">),</span> <span class="n">max_slice_nums</span><span class="p">)</span>

    <span class="c1"># 智能网格划分算法
</span>    <span class="k">if</span> <span class="n">multiple</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="p">{</span><span class="n">multiple</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">multiple</span><span class="p">,</span> <span class="n">multiple</span> <span class="o">+</span> <span class="mi">1</span><span class="p">}:</span>
            <span class="k">if</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="n">num</span> <span class="o">&lt;=</span> <span class="n">max_slice_nums</span><span class="p">:</span>
                <span class="n">m</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">while</span> <span class="n">m</span> <span class="o">*</span> <span class="n">m</span> <span class="o">&lt;=</span> <span class="n">num</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">num</span> <span class="o">%</span> <span class="n">m</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">candidates</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">num</span> <span class="o">//</span> <span class="n">m</span><span class="p">))</span>
                    <span class="n">m</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># 选择最接近原图长宽比的网格
</span>        <span class="n">log_ratio</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">original_width</span> <span class="o">/</span> <span class="n">original_height</span><span class="p">)</span>
        <span class="n">best_grid</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">candidates</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">g</span><span class="p">:</span> <span class="nf">abs</span><span class="p">(</span><span class="n">log_ratio</span> <span class="o">-</span> <span class="n">math</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
</code></pre></div></div> <p><strong>优化效果</strong>：这个改动将一个复杂的动态逻辑，简化为了C++中易于实现的纯数学运算。</p> <p><strong>优化策略二：用一次Permute操作统一几何变换</strong></p> <p><strong>问题背景</strong>：原始的图像切分和重排逻辑，涉及到多次<code class="language-plaintext highlighter-rouge">reshape</code>和<code class="language-plaintext highlighter-rouge">transpose</code>操作。这不仅代码繁琐，而且每次操作都可能触发内存拷贝，效率不高。</p> <p><strong>我们的解决方案</strong>：我们深入分析后发现，切图和重排的本质，都是在更高维度上对张量（Tensor）的数据进行位置重排。因此，这些看似复杂的多步操作，完全可以通过一次精心设计的<code class="language-plaintext highlighter-rouge">reshape</code>和一次<code class="language-plaintext highlighter-rouge">permute</code>（维度置换）操作来完成。</p> <p><strong>实现对比 (示意)</strong>：</p> <ul> <li> <strong>原始逻辑</strong>： <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="c1"># 步骤1：切分
</span><span class="n">patches</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(...)</span>
<span class="c1"># 步骤2：多次重排
</span><span class="n">temp1</span> <span class="o">=</span> <span class="n">patches</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(...)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">temp1</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(...).</span><span class="nf">transpose</span><span class="p">(...)</span>
</code></pre></div> </div> </li> <li> <strong>优化后逻辑</strong>： ```python <h1 id="一步到位">一步到位</h1> <h1 id="先构建一个包含所有维度信息的高维张量">先构建一个包含所有维度信息的高维张量</h1> <p>high_dim_tensor = images.reshape(…)</p> <h1 id="再通过一次permute完成所有数据的位置交换">再通过一次permute完成所有数据的位置交换</h1> <p>permuted_tensor = high_dim_tensor.permute(…) result = permuted_tensor.reshape(…) ```<strong>优化效果</strong>：这一改动对C++的实现极为友好。原本需要编写复杂循环和索引计算的代码，现在简化为对底层<code class="language-plaintext highlighter-rouge">permute</code>算子的一次调用，代码更简洁，执行效率也更高。</p> </li> </ul> <p><strong>优化策略三：为计算图导出重构推理逻辑</strong></p> <p><strong>问题背景</strong>：为了实现跨平台部署，模型必须能够导出计算图。</p> <p><strong>我们的解决方案</strong>：遵循“动静分离”的原则，我们将所有动态逻辑从模型的核心计算图中剥离出去。</p> <ul> <li> <strong>预处理阶段完成填充</strong>：在C++的图像预处理阶段，就将所有输入数据填充（Pad）到固定的最大尺寸。这样，送入模型的张量尺寸永远是静态的。</li> <li> <strong>简化和前置掩码计算</strong>：将动态生成注意力掩码（Attention Mask）的逻辑，同样移到模型外部的预处理环节。</li> <li> <strong>引入缓存机制</strong>：对于可复用的计算结果，如位置编码，我们增加了缓存，避免在每次推理中重复生成。</li> </ul> <p><strong>优化效果</strong>：经过重构，模型变成了一个完全静态的计算图，可以顺利地导出为ONNX文件，为最终在MNN上的高效运行铺平了道路。</p> <h2 id="模型推理">模型推理</h2> <p>理论层面的优化最终需要通过高效、稳健的代码实现来落地。我们将 MiniCPM 视觉处理的核心逻辑在 MNN 框架内，通过 C++ 进行了全面重构。下面，我们将详细拆解 <code class="language-plaintext highlighter-rouge">minicpmVisionProcess</code> 函数的实现，展示如何将优化思想转化为高性能的推理管线。</p> <h3 id="核心实现reoderimage-变换函数">核心实现：<code class="language-plaintext highlighter-rouge">reoderImage</code> 变换函数</h3> <p>整个流程中最精妙的部分被封装在一个名为 <code class="language-plaintext highlighter-rouge">reoderImage</code> 的 Lambda 函数中。它体现了<strong>优化策略二（用一次 Permute 统一几何变换）</strong>，负责将输入图像高效地缩放、切分并重排为模型所需的 Patch 序列。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">reoderImage</span> <span class="o">=</span> <span class="p">[</span><span class="k">this</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">patchSize</span><span class="p">](</span>
    <span class="n">Express</span><span class="o">::</span><span class="n">VARP</span> <span class="n">img</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="kt">int</span><span class="o">&gt;</span> <span class="n">targetSize</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">grid</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">tgtSize</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. 图像预处理：缩放、归一化、颜色空间转换</span>
    <span class="k">auto</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">MNN</span><span class="o">::</span><span class="n">CV</span><span class="o">::</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">...);</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">Express</span><span class="o">::</span><span class="n">_Convert</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="n">NCHW</span><span class="p">);</span>

    <span class="c1">// 2. 高效切片与重排的核心：Reshape -&gt; Permute -&gt; Reshape</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">Express</span><span class="o">::</span><span class="n">_Reshape</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="p">{</span>
        <span class="n">channel</span><span class="p">,</span> <span class="n">gridH</span><span class="p">,</span> <span class="n">numPatchesH</span><span class="p">,</span> <span class="n">patchSize</span><span class="p">,</span> <span class="n">gridW</span><span class="p">,</span> <span class="n">numPatchesW</span><span class="p">,</span> <span class="n">patchSize</span>
    <span class="p">});</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">Express</span><span class="o">::</span><span class="n">_Permute</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">});</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">Express</span><span class="o">::</span><span class="n">_Reshape</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="p">{</span>
        <span class="n">gridH</span> <span class="o">*</span> <span class="n">gridW</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">patchSize</span><span class="p">,</span> <span class="n">numPatchesH</span> <span class="o">*</span> <span class="n">numPatchesW</span> <span class="o">*</span> <span class="n">patchSize</span>
    <span class="p">});</span>
    <span class="c1">// ...</span>
    <span class="k">return</span> <span class="n">patches</span><span class="p">;</span>
<span class="p">};</span>
</code></pre></div></div> <p>此函数的核心在于，它将复杂的切图逻辑收敛到了一次 <code class="language-plaintext highlighter-rouge">_Permute</code> 原子操作。通过先 <code class="language-plaintext highlighter-rouge">_Reshape</code> 将图像张量提升到包含了网格、Patch、通道等所有几何信息的 7 维，然后一次 <code class="language-plaintext highlighter-rouge">_Permute</code> 就完成了所有数据块的位置交换，最后 <code class="language-plaintext highlighter-rouge">_Reshape</code> 回目标形状。这套操作避免了繁琐的循环和内存拷贝，为 C++ 的高性能实现提供了巨大便利。</p> <h3 id="静态模型输入构建">静态模型输入构建</h3> <p>遵循<strong>优化策略三（动静分离）</strong>的原则，我们在模型外部的 C++ 预处理阶段，准备好了 Vision Encoder 所需的全部四个静态输入张量。</p> <ol> <li> <strong><code class="language-plaintext highlighter-rouge">pixel_values</code> (像素值)</strong>: <div class="language-cpp highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">globalImage</span> <span class="o">=</span> <span class="n">reoderImage</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">globalSize</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">make_pair</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tgtSize</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">refineImage</span> <span class="o">=</span> <span class="n">reoderImage</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">refineSize</span><span class="p">,</span> <span class="n">sliceGrids</span><span class="p">,</span> <span class="n">tgtSize</span><span class="p">);</span>
<span class="c1">// 对 globalImage 进行 Padding，使其尺寸与 refineImage 对齐</span>
<span class="n">globalImage</span> <span class="o">=</span> <span class="n">_Pad</span><span class="p">(</span><span class="n">globalImage</span><span class="p">,</span> <span class="p">...);</span>
<span class="k">auto</span> <span class="n">pixel_values</span> <span class="o">=</span> <span class="n">_Concat</span><span class="p">({</span><span class="n">globalImage</span><span class="p">,</span> <span class="n">refineImage</span><span class="p">},</span> <span class="mi">0</span><span class="p">);</span>
</code></pre></div> </div> <p>我们分别对全局图像（1x1网格）和高清切片图像调用 <code class="language-plaintext highlighter-rouge">reoderImage</code>。然后，将较小的 <code class="language-plaintext highlighter-rouge">globalImage</code> 填充（Pad）到与 <code class="language-plaintext highlighter-rouge">refineImage</code> 相同的尺寸，最后将它们拼接（Concat）成一个 Batch，送入模型。所有动态尺寸处理都在模型外部完成。</p> </li> <li> <strong><code class="language-plaintext highlighter-rouge">position_ids</code> (位置ID)</strong>: <div class="language-cpp highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">h_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">h_idx</span> <span class="o">&lt;</span> <span class="n">nb_patches_h</span><span class="p">;</span> <span class="o">++</span><span class="n">h_idx</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">w_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">w_idx</span> <span class="o">&lt;</span> <span class="n">nb_patches_w</span><span class="p">;</span> <span class="o">++</span><span class="n">w_idx</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">long</span> <span class="n">bucket_h</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">h_idx</span> <span class="o">/</span> <span class="n">nb_patches_h</span><span class="p">)</span> <span class="o">*</span> <span class="n">patchesPerSide</span><span class="p">);</span>
        <span class="kt">long</span> <span class="n">bucket_w</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">w_idx</span> <span class="o">/</span> <span class="n">nb_patches_w</span><span class="p">)</span> <span class="o">*</span> <span class="n">patchesPerSide</span><span class="p">);</span>
        <span class="n">posPtr</span><span class="p">[...]</span> <span class="o">=</span> <span class="n">bucket_h</span> <span class="o">*</span> <span class="n">patchesPerSide</span> <span class="o">+</span> <span class="n">bucket_w</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div> </div> <p>这部分代码为每个 Patch 生成高精度的位置编码。它通过线性插值，将不同分辨率的 Patch 网格，统一映射到一个固定的 <code class="language-plaintext highlighter-rouge">patchesPerSide</code> x <code class="language-plaintext highlighter-rouge">patchesPerSide</code> 虚拟坐标系中，确保模型能准确理解每个 Patch 的相对空间位置。</p> </li> <li> <strong><code class="language-plaintext highlighter-rouge">attention_mask</code> (注意力掩码) 和 <code class="language-plaintext highlighter-rouge">tgt_sizes</code> (目标尺寸)</strong>: 我们同时生成 <code class="language-plaintext highlighter-rouge">attention_mask</code> 和 <code class="language-plaintext highlighter-rouge">tgt_sizes</code> 张量。前者用于在注意力计算中屏蔽掉因 Padding 产生的无效数据；后者则向模型传递每个切片的原始 Patch 尺寸，作为计算的元数据。</li> </ol> <h3 id="模型推理与多模态指令生成">模型推理与多模态指令生成</h3> <p>当所有输入张量准备就绪后，调用 MNN 引擎执行 Vision Encoder 的推理。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">imageEmbedding</span> <span class="o">=</span> <span class="n">mVisionModule</span><span class="o">-&gt;</span><span class="n">onForward</span><span class="p">({</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">position_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">tgt_sizes</span><span class="p">})[</span><span class="mi">0</span><span class="p">];</span>
</code></pre></div></div> <p>推理完成后，我们得到包含所有图像特征的 <code class="language-plaintext highlighter-rouge">imageEmbedding</code>。最后一步，是构建一个语言模型能够理解的“多模态指令”序列。</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">imgIds</span><span class="p">;</span>
<span class="c1">// 插入 &lt;image&gt; token 和 64 个 &lt;unk&gt; 占位符</span>
<span class="n">imgIds</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">mVisionStart</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="n">visionLen</span><span class="p">;</span> <span class="n">p</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">imgIds</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">mVisionPad</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">imgIds</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">mVisionEnd</span><span class="p">);</span>

<span class="c1">// 为每个 slice 插入 &lt;slice&gt; token 和 64 个 &lt;unk&gt; 占位符</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">B</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">imgIds</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">visionSliceStart</span><span class="p">);</span>
    <span class="c1">// ... 插入 64 个 &lt;unk&gt; 占位符 ...</span>
    <span class="n">imgIds</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">visionSliceEnd</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">return</span> <span class="n">imgIds</span><span class="p">;</span>
</code></pre></div></div> <p>这段代码使用特殊的 Token ID 来标记全局图像（<code class="language-plaintext highlighter-rouge">&lt;image&gt;</code>）和每个切片（<code class="language-plaintext highlighter-rouge">&lt;slice&gt;</code>）的边界，并在其中填充固定数量（64个）的占位符。这些占位符将在后续步骤中，被 <code class="language-plaintext highlighter-rouge">imageEmbedding</code> 中的实际视觉特征向量所替换，从而完成图文信息的最终融合。</p> <p>通过这套精心设计的 C++ 管线，一张原始图像被高效地转换为了一个结构精密、可供多模态大模型直接处理的输入序列，成功将算法原型产品化。</p> <h2 id="模型下载">模型下载</h2> <p>我们已经将转换好的 MNN 模型上传至社区，欢迎下载体验：</p> <ul> <li> <strong>ModelScope:</strong> <a href="https://modelscope.cn/models/MNN/MiniCPM-V-4-MNN" rel="external nofollow noopener" target="_blank">https://modelscope.cn/models/MNN/MiniCPM-V-4-MNN</a> </li> <li> <strong>Hugging Face:</strong> <a href="https://huggingface.co/taobao-mnn/MiniCPM-V-4-MNN" rel="external nofollow noopener" target="_blank">https://huggingface.co/taobao-mnn/MiniCPM-V-4-MNN</a> </li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/qwen3vl/">MNN模型支持：Qwen3-VL</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/qwenfamily/">一图读懂Qwen</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/device-llm-memory-capacity/">端侧LLM硬件系列（二）：内存容量</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/qwen3-next/">Qwen3-Next：下一代MoE模型架构解析</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/device-llm-memory-bandwidth/">端侧LLM硬件系列（一）：内存带宽</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Zhaode Wang. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>